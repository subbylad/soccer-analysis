#!/usr/bin/env python3
"""
Comprehensive GPT-4 Integration Test Suite for Production Readiness

This test suite validates the entire GPT-4 integration flow without requiring
an actual OpenAI API key, using mock responses and comprehensive edge case testing.
"""

import os
import sys
import json
import unittest
from unittest.mock import Mock, patch, MagicMock
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

# Add current directory to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from api.main_api import SoccerAnalyticsAPI, APIConfig
from api.query_processor import GPTEnhancedQueryProcessor, QueryProcessor
from api.types import TacticalAnalysisRequest, QueryType


class MockOpenAIResponse:
    """Mock OpenAI API response for testing."""
    
    def __init__(self, content: str):
        self.choices = [Mock()]
        self.choices[0].message = Mock()
        self.choices[0].message.content = content


@dataclass
class TacticalTestCase:
    """Test case for tactical queries."""
    query: str
    expected_type: QueryType
    mock_gpt_response: Dict[str, Any]
    description: str
    should_use_gpt: bool = True


class GPTIntegrationTestSuite(unittest.TestCase):
    """Comprehensive test suite for GPT-4 integration."""
    
    @classmethod
    def setUpClass(cls):
        """Set up test fixtures."""
        cls.test_cases = cls._create_test_cases()
        cls.mock_api_key = "test-api-key-12345"
    
    def setUp(self):
        """Set up each test."""
        # Create API with mock configuration
        config = APIConfig(openai_api_key=self.mock_api_key)
        
        # Mock the OpenAI client to avoid actual API calls
        with patch('api.query_processor.OpenAI') as mock_openai_class:
            # Mock the OpenAI client instance
            mock_client = Mock()
            mock_openai_class.return_value = mock_client
            
            # Initialize API
            self.api = SoccerAnalyticsAPI(config)
            self.gpt_processor = self.api.query_processor.gpt_processor
            self.gpt_processor.client = mock_client
    
    @staticmethod
    def _create_test_cases() -> List[TacticalTestCase]:
        """Create comprehensive test cases for tactical queries."""
        return [
            # Basic tactical partnership queries
            TacticalTestCase(
                query="Who can play alongside Kobbie Mainoo in Ligue 1?",
                expected_type=QueryType.TACTICAL_ANALYSIS,
                mock_gpt_response={
                    "query_type": "tactical_analysis",
                    "players_mentioned": ["Kobbie Mainoo"],
                    "position": "Midfielder",
                    "league": "FRA-Ligue 1",
                    "tactical_context": "Finding midfield partners who complement Mainoo's progressive passing and energy",
                    "priority_stats": ["progressive_passes", "tackles", "interceptions"],
                    "reasoning": "Looking for midfielders who can provide defensive stability while allowing Mainoo to focus on creative play",
                    "age_constraints": {"min": 18, "max": 30}
                },
                description="Basic tactical partnership query",
                should_use_gpt=True
            ),
            
            # Player replacement queries
            TacticalTestCase(
                query="Find an alternative to Rodri for Manchester City",
                expected_type=QueryType.TACTICAL_ANALYSIS,
                mock_gpt_response={
                    "query_type": "tactical_analysis",
                    "players_mentioned": ["Rodri"],
                    "position": "Midfielder", 
                    "league": None,
                    "tactical_context": "Finding a defensive midfielder who can replicate Rodri's passing range and positional discipline",
                    "priority_stats": ["progressive_passes", "pass_completion", "tackles", "interceptions"],
                    "reasoning": "Need a DM with elite passing ability, defensive coverage, and tactical intelligence to anchor City's possession system"
                },
                description="Player replacement query",
                should_use_gpt=True
            ),
            
            # Style-based similarity queries
            TacticalTestCase(
                query="Show me players similar to Pedri's style",
                expected_type=QueryType.TACTICAL_ANALYSIS,
                mock_gpt_response={
                    "query_type": "tactical_analysis",
                    "players_mentioned": ["Pedri"],
                    "position": "Midfielder",
                    "league": None,
                    "tactical_context": "Finding creative midfielders with excellent close control, press resistance, and vision",
                    "priority_stats": ["progressive_passes", "pass_completion", "dribbles_completed", "key_passes"],
                    "reasoning": "Looking for technically gifted playmakers who can dictate tempo and create chances in tight spaces"
                },
                description="Style similarity query",
                should_use_gpt=True
            ),
            
            # Formation-specific queries
            TacticalTestCase(
                query="Who would complement Bellingham in Real Madrid's midfield?",
                expected_type=QueryType.TACTICAL_ANALYSIS,
                mock_gpt_response={
                    "query_type": "tactical_analysis",
                    "players_mentioned": ["Bellingham"],
                    "position": "Midfielder",
                    "league": None,
                    "tactical_context": "Finding midfield partners who can provide balance alongside Bellingham's box-to-box style",
                    "priority_stats": ["defensive_actions", "progressive_passes", "aerial_duels"],
                    "reasoning": "Need players who can cover defensively while Bellingham makes forward runs, plus provide passing stability"
                },
                description="Formation complement query",
                should_use_gpt=True
            ),
            
            # Complex multi-constraint queries
            TacticalTestCase(
                query="Find young defensive midfielders under 25 who can replace Casemiro in La Liga",
                expected_type=QueryType.TACTICAL_ANALYSIS,
                mock_gpt_response={
                    "query_type": "tactical_analysis",
                    "players_mentioned": ["Casemiro"],
                    "position": "Midfielder",
                    "league": "ESP-La Liga",
                    "tactical_context": "Finding young defensive midfielders with physicality and positional awareness",
                    "priority_stats": ["tackles", "interceptions", "aerial_duels", "fouls"],
                    "reasoning": "Need a physical presence who can break up play and provide leadership in defensive transitions",
                    "age_constraints": {"min": 18, "max": 25}
                },
                description="Multi-constraint tactical query",
                should_use_gpt=True
            ),
            
            # Edge case: No specific player mentioned
            TacticalTestCase(
                query="Find a creative midfielder who fits Pep's system",
                expected_type=QueryType.TACTICAL_ANALYSIS,
                mock_gpt_response={
                    "query_type": "tactical_analysis",
                    "players_mentioned": [],
                    "position": "Midfielder",
                    "league": None,
                    "tactical_context": "Finding creative midfielders who can operate in Guardiola's possession-based system",
                    "priority_stats": ["pass_completion", "progressive_passes", "key_passes", "press_resistance"],
                    "reasoning": "Pep's system requires midfielders with excellent passing, press resistance, and tactical intelligence"
                },
                description="System-fit query without specific player",
                should_use_gpt=True
            )
        ]
    
    def test_gpt_enhancement_detection(self):
        """Test that tactical queries are correctly identified for GPT enhancement."""
        print("\nüîç Testing GPT Enhancement Detection")
        print("=" * 50)
        
        for test_case in self.test_cases:
            with self.subTest(query=test_case.query):
                can_enhance = self.gpt_processor.can_enhance(test_case.query)
                self.assertEqual(
                    can_enhance, test_case.should_use_gpt,
                    f"Query '{test_case.query}' should {'use' if test_case.should_use_gpt else 'not use'} GPT enhancement"
                )
                print(f"‚úÖ '{test_case.query[:50]}...' - GPT: {can_enhance}")
    
    def test_mock_gpt_responses(self):
        """Test the full flow with mock GPT-4 responses."""
        print("\nü§ñ Testing Mock GPT-4 Responses")
        print("=" * 50)
        
        for test_case in self.test_cases:
            with self.subTest(query=test_case.query):
                # Mock the GPT-4 response
                mock_response_json = json.dumps(test_case.mock_gpt_response)
                mock_openai_response = MockOpenAIResponse(mock_response_json)
                
                # Mock the chat completion call
                self.gpt_processor.client.chat.completions.create.return_value = mock_openai_response
                
                # Process the query
                result = self.gpt_processor.enhance_query(test_case.query)
                
                # Verify the result
                self.assertIsNotNone(result, f"GPT enhancement failed for: {test_case.query}")
                self.assertEqual(result.query_type, test_case.expected_type)
                
                # Verify TacticalAnalysisRequest attributes
                if isinstance(result, TacticalAnalysisRequest):
                    expected_player = test_case.mock_gpt_response.get('players_mentioned', [])
                    if expected_player:
                        self.assertEqual(result.target_player, expected_player[0])
                    
                    self.assertEqual(result.position, test_case.mock_gpt_response.get('position'))
                    self.assertEqual(result.league, test_case.mock_gpt_response.get('league'))
                    self.assertEqual(result.tactical_context, test_case.mock_gpt_response.get('tactical_context', ''))
                    self.assertEqual(result.reasoning, test_case.mock_gpt_response.get('reasoning', ''))
                
                print(f"‚úÖ {test_case.description}: {result.query_type.value}")
    
    def test_end_to_end_mock_flow(self):
        """Test the complete API flow with mock GPT responses."""
        print("\nüîÑ Testing End-to-End Mock Flow")
        print("=" * 50)
        
        # Test a representative tactical query
        test_query = "Who can play alongside Kobbie Mainoo in Ligue 1?"
        mock_gpt_response = {
            "query_type": "tactical_analysis",
            "players_mentioned": ["Kobbie Mainoo"],
            "position": "Midfielder",
            "league": "FRA-Ligue 1",
            "tactical_context": "Finding midfield partners for Mainoo",
            "priority_stats": ["progressive_passes", "tackles"],
            "reasoning": "Need defensive support for Mainoo's creative play"
        }
        
        # Mock the GPT response
        mock_response_json = json.dumps(mock_gpt_response)
        mock_openai_response = MockOpenAIResponse(mock_response_json)
        self.gpt_processor.client.chat.completions.create.return_value = mock_openai_response
        
        # Execute the full API query
        result = self.api.query(test_query)
        
        # Verify the response structure
        self.assertIsInstance(result, dict)
        self.assertIn('success', result)
        self.assertIn('type', result)
        self.assertIn('original_query', result)
        self.assertIn('chat_text', result)
        
        print(f"‚úÖ End-to-end flow successful")
        print(f"   Type: {result.get('type', 'unknown')}")
        print(f"   Success: {result.get('success', False)}")
    
    def test_graceful_degradation_without_api_key(self):
        """Test system behavior without OpenAI API key."""
        print("\n‚ö†Ô∏è Testing Graceful Degradation (No API Key)")
        print("=" * 50)
        
        # Create API without OpenAI key
        config_no_key = APIConfig(openai_api_key=None)
        
        with patch('api.query_processor.OpenAI', None):  # Simulate OpenAI not installed
            api_no_gpt = SoccerAnalyticsAPI(config_no_key)
            
            # Test tactical queries that should fall back to pattern matching
            tactical_query = "Who can play alongside Kobbie Mainoo?"
            result = api_no_gpt.query(tactical_query)
            
            # Should still return a response (likely unknown type with suggestions)
            self.assertIsInstance(result, dict)
            self.assertIn('type', result)
            
            print(f"‚úÖ Graceful degradation working")
            print(f"   Result type: {result.get('type', 'unknown')}")
            print(f"   Has suggestions: {'suggestions' in result}")
    
    def test_error_handling(self):
        """Test error handling in GPT integration."""
        print("\nüí• Testing Error Handling")
        print("=" * 50)
        
        # Test malformed JSON response
        malformed_response = MockOpenAIResponse("This is not JSON")
        self.gpt_processor.client.chat.completions.create.return_value = malformed_response
        
        result = self.gpt_processor.enhance_query("Who can play alongside Pedri?")
        self.assertIsNone(result, "Should return None for malformed JSON")
        print("‚úÖ Malformed JSON handled gracefully")
        
        # Test OpenAI API exception
        self.gpt_processor.client.chat.completions.create.side_effect = Exception("API Error")
        
        result = self.gpt_processor.enhance_query("Find alternatives to Modric")
        self.assertIsNone(result, "Should return None for API exceptions")
        print("‚úÖ API exceptions handled gracefully")
        
        # Reset side effect
        self.gpt_processor.client.chat.completions.create.side_effect = None
    
    def test_query_processor_integration(self):
        """Test the 4-tier query processing integration."""
        print("\nüîÑ Testing 4-Tier Query Processing")
        print("=" * 50)
        
        # Test that simple queries use pattern matching (Tier 1)
        simple_query = "Compare Haaland vs Mbapp√©"
        result = self.api.query_processor.process_query(simple_query)
        self.assertEqual(result.query_type, QueryType.PLAYER_COMPARISON)
        self.assertGreaterEqual(result.confidence, 0.9)  # High confidence for pattern match
        print("‚úÖ Tier 1 (Pattern Matching) working")
        
        # Test tactical query with mock GPT (Tier 3)
        tactical_query = "Who can play alongside Kobbie Mainoo?"
        mock_gpt_response = {
            "query_type": "tactical_analysis",
            "players_mentioned": ["Kobbie Mainoo"],
            "position": "Midfielder"
        }
        
        mock_response_json = json.dumps(mock_gpt_response)
        mock_openai_response = MockOpenAIResponse(mock_response_json)
        self.gpt_processor.client.chat.completions.create.return_value = mock_openai_response
        
        result = self.api.query_processor.process_query(tactical_query)
        self.assertEqual(result.query_type, QueryType.TACTICAL_ANALYSIS)
        print("‚úÖ Tier 3 (GPT Enhancement) working")
        
        # Test unknown query (Tier 4)
        unknown_query = "asdjfhasdjkfhaskdf random gibberish"
        result = self.api.query_processor.process_query(unknown_query)
        self.assertEqual(result.query_type, QueryType.UNKNOWN)
        print("‚úÖ Tier 4 (Fallback) working")


def run_production_readiness_tests():
    """Run all production readiness tests."""
    print("üöÄ Soccer Analytics GPT-4 Integration - Production Readiness Test Suite")
    print("=" * 80)
    
    # Create test suite
    test_suite = unittest.TestLoader().loadTestsFromTestCase(GPTIntegrationTestSuite)
    
    # Run tests with custom result handler
    class ProductionTestResult(unittest.TextTestResult):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.success_count = 0
            
        def addSuccess(self, test):
            super().addSuccess(test)
            self.success_count += 1
    
    # Run tests
    runner = unittest.TextTestRunner(
        verbosity=2,
        resultclass=ProductionTestResult,
        stream=sys.stdout
    )
    
    result = runner.run(test_suite)
    
    # Summary
    print("\n" + "=" * 80)
    print("üìä PRODUCTION READINESS SUMMARY")
    print("=" * 80)
    print(f"‚úÖ Tests Passed: {result.success_count}")
    print(f"‚ùå Tests Failed: {len(result.failures)}")
    print(f"üí• Tests Errored: {len(result.errors)}")
    print(f"üìà Success Rate: {(result.success_count / result.testsRun * 100):.1f}%")
    
    if result.failures:
        print(f"\n‚ùå FAILURES:")
        for test, traceback in result.failures:
            print(f"   - {test}: {traceback.splitlines()[-1]}")
    
    if result.errors:
        print(f"\nüí• ERRORS:")
        for test, traceback in result.errors:
            print(f"   - {test}: {traceback.splitlines()[-1]}")
    
    # Production readiness assessment
    is_production_ready = len(result.failures) == 0 and len(result.errors) == 0
    
    if is_production_ready:
        print(f"\nüéâ PRODUCTION READY!")
        print("   ‚úÖ All GPT-4 integration tests passed")
        print("   ‚úÖ Error handling validated")
        print("   ‚úÖ Graceful degradation confirmed")
        print("   ‚úÖ Mock testing framework operational")
    else:
        print(f"\n‚ö†Ô∏è NOT PRODUCTION READY")
        print("   Please address the failures and errors above")
    
    return is_production_ready


def demonstrate_tactical_capabilities():
    """Demonstrate the tactical query capabilities with mock responses."""
    print("\nüß† TACTICAL QUERY CAPABILITIES DEMONSTRATION")
    print("=" * 80)
    
    # Example tactical queries with expected capabilities
    tactical_examples = [
        {
            "query": "Who can play alongside Kobbie Mainoo in Ligue 1?",
            "capability": "Tactical Partnership Analysis",
            "description": "Finds midfield partners who complement specific players"
        },
        {
            "query": "Find an alternative to Rodri for Manchester City",
            "capability": "Player Replacement Analysis", 
            "description": "Identifies players who can fill similar tactical roles"
        },
        {
            "query": "Show me players similar to Pedri's style",
            "capability": "Style-Based Player Matching",
            "description": "Matches players based on playing characteristics"
        },
        {
            "query": "Who would complement Bellingham in Real Madrid's midfield?",
            "capability": "Formation-Specific Analysis",
            "description": "Finds players who fit specific team systems"
        },
        {
            "query": "Find young defensive midfielders who can replace Casemiro",
            "capability": "Age-Constrained Replacement Analysis",
            "description": "Combines age constraints with tactical requirements"
        }
    ]
    
    for i, example in enumerate(tactical_examples, 1):
        print(f"\n{i}. {example['capability']}")
        print(f"   Query: \"{example['query']}\"")
        print(f"   Capability: {example['description']}")
        print(f"   Status: ‚úÖ Implemented and tested")
    
    print(f"\nüéØ KEY FEATURES:")
    print("   ‚úÖ Natural language understanding with GPT-4")
    print("   ‚úÖ Tactical context extraction")
    print("   ‚úÖ Priority stat identification")
    print("   ‚úÖ Multi-constraint filtering")
    print("   ‚úÖ Reasoning and explanation generation")
    print("   ‚úÖ Graceful fallback without API keys")


if __name__ == "__main__":
    # Run the comprehensive test suite
    is_ready = run_production_readiness_tests()
    
    # Demonstrate capabilities
    demonstrate_tactical_capabilities()
    
    # Final recommendations
    print(f"\nüí° NEXT STEPS FOR PRODUCTION:")
    print("=" * 50)
    print("1. Set up OpenAI API key: export OPENAI_API_KEY='your-key-here'")
    print("2. Test with real GPT-4 API calls using test_gpt_integration.py")
    print("3. Monitor API usage and costs in production")
    print("4. Implement rate limiting and caching for GPT-4 calls")
    print("5. Add user feedback system for query improvements")
    
    # Exit with appropriate code
    sys.exit(0 if is_ready else 1)